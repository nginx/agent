// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeNginxByteIoDirection specifies the a value nginx.byte.io.direction attribute.
type AttributeNginxByteIoDirection int

const (
	_ AttributeNginxByteIoDirection = iota
	AttributeNginxByteIoDirectionRX
	AttributeNginxByteIoDirectionTX
)

// String returns the string representation of the AttributeNginxByteIoDirection.
func (av AttributeNginxByteIoDirection) String() string {
	switch av {
	case AttributeNginxByteIoDirectionRX:
		return "RX"
	case AttributeNginxByteIoDirectionTX:
		return "TX"
	}
	return ""
}

// MapAttributeNginxByteIoDirection is a helper map of string to AttributeNginxByteIoDirection attribute value.
var MapAttributeNginxByteIoDirection = map[string]AttributeNginxByteIoDirection{
	"RX": AttributeNginxByteIoDirectionRX,
	"TX": AttributeNginxByteIoDirectionTX,
}

// AttributeNginxCacheOutcome specifies the a value nginx.cache.outcome attribute.
type AttributeNginxCacheOutcome int

const (
	_ AttributeNginxCacheOutcome = iota
	AttributeNginxCacheOutcomeBYPASS
	AttributeNginxCacheOutcomeEXPIRED
	AttributeNginxCacheOutcomeHIT
	AttributeNginxCacheOutcomeMISS
	AttributeNginxCacheOutcomeREVALIDATED
	AttributeNginxCacheOutcomeSTALE
	AttributeNginxCacheOutcomeUPDATING
)

// String returns the string representation of the AttributeNginxCacheOutcome.
func (av AttributeNginxCacheOutcome) String() string {
	switch av {
	case AttributeNginxCacheOutcomeBYPASS:
		return "BYPASS"
	case AttributeNginxCacheOutcomeEXPIRED:
		return "EXPIRED"
	case AttributeNginxCacheOutcomeHIT:
		return "HIT"
	case AttributeNginxCacheOutcomeMISS:
		return "MISS"
	case AttributeNginxCacheOutcomeREVALIDATED:
		return "REVALIDATED"
	case AttributeNginxCacheOutcomeSTALE:
		return "STALE"
	case AttributeNginxCacheOutcomeUPDATING:
		return "UPDATING"
	}
	return ""
}

// MapAttributeNginxCacheOutcome is a helper map of string to AttributeNginxCacheOutcome attribute value.
var MapAttributeNginxCacheOutcome = map[string]AttributeNginxCacheOutcome{
	"BYPASS":      AttributeNginxCacheOutcomeBYPASS,
	"EXPIRED":     AttributeNginxCacheOutcomeEXPIRED,
	"HIT":         AttributeNginxCacheOutcomeHIT,
	"MISS":        AttributeNginxCacheOutcomeMISS,
	"REVALIDATED": AttributeNginxCacheOutcomeREVALIDATED,
	"STALE":       AttributeNginxCacheOutcomeSTALE,
	"UPDATING":    AttributeNginxCacheOutcomeUPDATING,
}

// AttributeNginxConnOutcome specifies the a value nginx.conn.outcome attribute.
type AttributeNginxConnOutcome int

const (
	_ AttributeNginxConnOutcome = iota
	AttributeNginxConnOutcomeACCEPTED
	AttributeNginxConnOutcomeACTIVE
	AttributeNginxConnOutcomeDROPPED
	AttributeNginxConnOutcomeIDLE
)

// String returns the string representation of the AttributeNginxConnOutcome.
func (av AttributeNginxConnOutcome) String() string {
	switch av {
	case AttributeNginxConnOutcomeACCEPTED:
		return "ACCEPTED"
	case AttributeNginxConnOutcomeACTIVE:
		return "ACTIVE"
	case AttributeNginxConnOutcomeDROPPED:
		return "DROPPED"
	case AttributeNginxConnOutcomeIDLE:
		return "IDLE"
	}
	return ""
}

// MapAttributeNginxConnOutcome is a helper map of string to AttributeNginxConnOutcome attribute value.
var MapAttributeNginxConnOutcome = map[string]AttributeNginxConnOutcome{
	"ACCEPTED": AttributeNginxConnOutcomeACCEPTED,
	"ACTIVE":   AttributeNginxConnOutcomeACTIVE,
	"DROPPED":  AttributeNginxConnOutcomeDROPPED,
	"IDLE":     AttributeNginxConnOutcomeIDLE,
}

// AttributeNginxHealthCheck specifies the a value nginx.health_check attribute.
type AttributeNginxHealthCheck int

const (
	_ AttributeNginxHealthCheck = iota
	AttributeNginxHealthCheckUNHEALTHY
	AttributeNginxHealthCheckFAIL
)

// String returns the string representation of the AttributeNginxHealthCheck.
func (av AttributeNginxHealthCheck) String() string {
	switch av {
	case AttributeNginxHealthCheckUNHEALTHY:
		return "UNHEALTHY"
	case AttributeNginxHealthCheckFAIL:
		return "FAIL"
	}
	return ""
}

// MapAttributeNginxHealthCheck is a helper map of string to AttributeNginxHealthCheck attribute value.
var MapAttributeNginxHealthCheck = map[string]AttributeNginxHealthCheck{
	"UNHEALTHY": AttributeNginxHealthCheckUNHEALTHY,
	"FAIL":      AttributeNginxHealthCheckFAIL,
}

// AttributeNginxLimitConnOutcome specifies the a value nginx.limit_conn.outcome attribute.
type AttributeNginxLimitConnOutcome int

const (
	_ AttributeNginxLimitConnOutcome = iota
	AttributeNginxLimitConnOutcomePASSED
	AttributeNginxLimitConnOutcomeREJECTED
	AttributeNginxLimitConnOutcomeREJECTEDDRYRUN
)

// String returns the string representation of the AttributeNginxLimitConnOutcome.
func (av AttributeNginxLimitConnOutcome) String() string {
	switch av {
	case AttributeNginxLimitConnOutcomePASSED:
		return "PASSED"
	case AttributeNginxLimitConnOutcomeREJECTED:
		return "REJECTED"
	case AttributeNginxLimitConnOutcomeREJECTEDDRYRUN:
		return "REJECTED_DRY_RUN"
	}
	return ""
}

// MapAttributeNginxLimitConnOutcome is a helper map of string to AttributeNginxLimitConnOutcome attribute value.
var MapAttributeNginxLimitConnOutcome = map[string]AttributeNginxLimitConnOutcome{
	"PASSED":           AttributeNginxLimitConnOutcomePASSED,
	"REJECTED":         AttributeNginxLimitConnOutcomeREJECTED,
	"REJECTED_DRY_RUN": AttributeNginxLimitConnOutcomeREJECTEDDRYRUN,
}

// AttributeNginxLimitReqOutcome specifies the a value nginx.limit_req.outcome attribute.
type AttributeNginxLimitReqOutcome int

const (
	_ AttributeNginxLimitReqOutcome = iota
	AttributeNginxLimitReqOutcomePASSED
	AttributeNginxLimitReqOutcomeREJECTED
	AttributeNginxLimitReqOutcomeREJECTEDDRYRUN
	AttributeNginxLimitReqOutcomeDELAYED
	AttributeNginxLimitReqOutcomeDELAYEDDRYRUN
)

// String returns the string representation of the AttributeNginxLimitReqOutcome.
func (av AttributeNginxLimitReqOutcome) String() string {
	switch av {
	case AttributeNginxLimitReqOutcomePASSED:
		return "PASSED"
	case AttributeNginxLimitReqOutcomeREJECTED:
		return "REJECTED"
	case AttributeNginxLimitReqOutcomeREJECTEDDRYRUN:
		return "REJECTED_DRY_RUN"
	case AttributeNginxLimitReqOutcomeDELAYED:
		return "DELAYED"
	case AttributeNginxLimitReqOutcomeDELAYEDDRYRUN:
		return "DELAYED_DRY_RUN"
	}
	return ""
}

// MapAttributeNginxLimitReqOutcome is a helper map of string to AttributeNginxLimitReqOutcome attribute value.
var MapAttributeNginxLimitReqOutcome = map[string]AttributeNginxLimitReqOutcome{
	"PASSED":           AttributeNginxLimitReqOutcomePASSED,
	"REJECTED":         AttributeNginxLimitReqOutcomeREJECTED,
	"REJECTED_DRY_RUN": AttributeNginxLimitReqOutcomeREJECTEDDRYRUN,
	"DELAYED":          AttributeNginxLimitReqOutcomeDELAYED,
	"DELAYED_DRY_RUN":  AttributeNginxLimitReqOutcomeDELAYEDDRYRUN,
}

// AttributeNginxPeerState specifies the a value nginx.peer.state attribute.
type AttributeNginxPeerState int

const (
	_ AttributeNginxPeerState = iota
	AttributeNginxPeerStateCHECKING
	AttributeNginxPeerStateDOWN
	AttributeNginxPeerStateDRAINING
	AttributeNginxPeerStateUNAVAILABLE
	AttributeNginxPeerStateUNHEALTHY
	AttributeNginxPeerStateUP
)

// String returns the string representation of the AttributeNginxPeerState.
func (av AttributeNginxPeerState) String() string {
	switch av {
	case AttributeNginxPeerStateCHECKING:
		return "CHECKING"
	case AttributeNginxPeerStateDOWN:
		return "DOWN"
	case AttributeNginxPeerStateDRAINING:
		return "DRAINING"
	case AttributeNginxPeerStateUNAVAILABLE:
		return "UNAVAILABLE"
	case AttributeNginxPeerStateUNHEALTHY:
		return "UNHEALTHY"
	case AttributeNginxPeerStateUP:
		return "UP"
	}
	return ""
}

// MapAttributeNginxPeerState is a helper map of string to AttributeNginxPeerState attribute value.
var MapAttributeNginxPeerState = map[string]AttributeNginxPeerState{
	"CHECKING":    AttributeNginxPeerStateCHECKING,
	"DOWN":        AttributeNginxPeerStateDOWN,
	"DRAINING":    AttributeNginxPeerStateDRAINING,
	"UNAVAILABLE": AttributeNginxPeerStateUNAVAILABLE,
	"UNHEALTHY":   AttributeNginxPeerStateUNHEALTHY,
	"UP":          AttributeNginxPeerStateUP,
}

// AttributeNginxSlabSlotAllocationResult specifies the a value nginx.slab.slot.allocation.result attribute.
type AttributeNginxSlabSlotAllocationResult int

const (
	_ AttributeNginxSlabSlotAllocationResult = iota
	AttributeNginxSlabSlotAllocationResultFAILURE
	AttributeNginxSlabSlotAllocationResultSUCCESS
)

// String returns the string representation of the AttributeNginxSlabSlotAllocationResult.
func (av AttributeNginxSlabSlotAllocationResult) String() string {
	switch av {
	case AttributeNginxSlabSlotAllocationResultFAILURE:
		return "FAILURE"
	case AttributeNginxSlabSlotAllocationResultSUCCESS:
		return "SUCCESS"
	}
	return ""
}

// MapAttributeNginxSlabSlotAllocationResult is a helper map of string to AttributeNginxSlabSlotAllocationResult attribute value.
var MapAttributeNginxSlabSlotAllocationResult = map[string]AttributeNginxSlabSlotAllocationResult{
	"FAILURE": AttributeNginxSlabSlotAllocationResultFAILURE,
	"SUCCESS": AttributeNginxSlabSlotAllocationResultSUCCESS,
}

// AttributeNginxSslHandshakeReason specifies the a value nginx.ssl.handshake.reason attribute.
type AttributeNginxSslHandshakeReason int

const (
	_ AttributeNginxSslHandshakeReason = iota
	AttributeNginxSslHandshakeReasonNOCOMMONPROTOCOL
	AttributeNginxSslHandshakeReasonNOCOMMONCIPHER
	AttributeNginxSslHandshakeReasonTIMEOUT
	AttributeNginxSslHandshakeReasonCERTREJECTED
)

// String returns the string representation of the AttributeNginxSslHandshakeReason.
func (av AttributeNginxSslHandshakeReason) String() string {
	switch av {
	case AttributeNginxSslHandshakeReasonNOCOMMONPROTOCOL:
		return "NO_COMMON_PROTOCOL"
	case AttributeNginxSslHandshakeReasonNOCOMMONCIPHER:
		return "NO_COMMON_CIPHER"
	case AttributeNginxSslHandshakeReasonTIMEOUT:
		return "TIMEOUT"
	case AttributeNginxSslHandshakeReasonCERTREJECTED:
		return "CERT_REJECTED"
	}
	return ""
}

// MapAttributeNginxSslHandshakeReason is a helper map of string to AttributeNginxSslHandshakeReason attribute value.
var MapAttributeNginxSslHandshakeReason = map[string]AttributeNginxSslHandshakeReason{
	"NO_COMMON_PROTOCOL": AttributeNginxSslHandshakeReasonNOCOMMONPROTOCOL,
	"NO_COMMON_CIPHER":   AttributeNginxSslHandshakeReasonNOCOMMONCIPHER,
	"TIMEOUT":            AttributeNginxSslHandshakeReasonTIMEOUT,
	"CERT_REJECTED":      AttributeNginxSslHandshakeReasonCERTREJECTED,
}

// AttributeNginxSslStatus specifies the a value nginx.ssl.status attribute.
type AttributeNginxSslStatus int

const (
	_ AttributeNginxSslStatus = iota
	AttributeNginxSslStatusFAILED
	AttributeNginxSslStatusREUSE
)

// String returns the string representation of the AttributeNginxSslStatus.
func (av AttributeNginxSslStatus) String() string {
	switch av {
	case AttributeNginxSslStatusFAILED:
		return "FAILED"
	case AttributeNginxSslStatusREUSE:
		return "REUSE"
	}
	return ""
}

// MapAttributeNginxSslStatus is a helper map of string to AttributeNginxSslStatus attribute value.
var MapAttributeNginxSslStatus = map[string]AttributeNginxSslStatus{
	"FAILED": AttributeNginxSslStatusFAILED,
	"REUSE":  AttributeNginxSslStatusREUSE,
}

// AttributeNginxSslVerifyFailureReason specifies the a value nginx.ssl.verify_failure.reason attribute.
type AttributeNginxSslVerifyFailureReason int

const (
	_ AttributeNginxSslVerifyFailureReason = iota
	AttributeNginxSslVerifyFailureReasonNOCERT
	AttributeNginxSslVerifyFailureReasonEXPIREDCERT
	AttributeNginxSslVerifyFailureReasonREVOKEDCERT
	AttributeNginxSslVerifyFailureReasonHOSTNAMEMISMATCH
	AttributeNginxSslVerifyFailureReasonOTHER
)

// String returns the string representation of the AttributeNginxSslVerifyFailureReason.
func (av AttributeNginxSslVerifyFailureReason) String() string {
	switch av {
	case AttributeNginxSslVerifyFailureReasonNOCERT:
		return "NO_CERT"
	case AttributeNginxSslVerifyFailureReasonEXPIREDCERT:
		return "EXPIRED_CERT"
	case AttributeNginxSslVerifyFailureReasonREVOKEDCERT:
		return "REVOKED_CERT"
	case AttributeNginxSslVerifyFailureReasonHOSTNAMEMISMATCH:
		return "HOSTNAME_MISMATCH"
	case AttributeNginxSslVerifyFailureReasonOTHER:
		return "OTHER"
	}
	return ""
}

// MapAttributeNginxSslVerifyFailureReason is a helper map of string to AttributeNginxSslVerifyFailureReason attribute value.
var MapAttributeNginxSslVerifyFailureReason = map[string]AttributeNginxSslVerifyFailureReason{
	"NO_CERT":           AttributeNginxSslVerifyFailureReasonNOCERT,
	"EXPIRED_CERT":      AttributeNginxSslVerifyFailureReasonEXPIREDCERT,
	"REVOKED_CERT":      AttributeNginxSslVerifyFailureReasonREVOKEDCERT,
	"HOSTNAME_MISMATCH": AttributeNginxSslVerifyFailureReasonHOSTNAMEMISMATCH,
	"OTHER":             AttributeNginxSslVerifyFailureReasonOTHER,
}

// AttributeNginxStatusRange specifies the a value nginx.status_range attribute.
type AttributeNginxStatusRange int

const (
	_ AttributeNginxStatusRange = iota
	AttributeNginxStatusRange1xx
	AttributeNginxStatusRange2xx
	AttributeNginxStatusRange3xx
	AttributeNginxStatusRange4xx
	AttributeNginxStatusRange5xx
)

// String returns the string representation of the AttributeNginxStatusRange.
func (av AttributeNginxStatusRange) String() string {
	switch av {
	case AttributeNginxStatusRange1xx:
		return "1xx"
	case AttributeNginxStatusRange2xx:
		return "2xx"
	case AttributeNginxStatusRange3xx:
		return "3xx"
	case AttributeNginxStatusRange4xx:
		return "4xx"
	case AttributeNginxStatusRange5xx:
		return "5xx"
	}
	return ""
}

// MapAttributeNginxStatusRange is a helper map of string to AttributeNginxStatusRange attribute value.
var MapAttributeNginxStatusRange = map[string]AttributeNginxStatusRange{
	"1xx": AttributeNginxStatusRange1xx,
	"2xx": AttributeNginxStatusRange2xx,
	"3xx": AttributeNginxStatusRange3xx,
	"4xx": AttributeNginxStatusRange4xx,
	"5xx": AttributeNginxStatusRange5xx,
}

// AttributeNginxZoneType specifies the a value nginx.zone.type attribute.
type AttributeNginxZoneType int

const (
	_ AttributeNginxZoneType = iota
	AttributeNginxZoneTypeSERVER
	AttributeNginxZoneTypeLOCATION
)

// String returns the string representation of the AttributeNginxZoneType.
func (av AttributeNginxZoneType) String() string {
	switch av {
	case AttributeNginxZoneTypeSERVER:
		return "SERVER"
	case AttributeNginxZoneTypeLOCATION:
		return "LOCATION"
	}
	return ""
}

// MapAttributeNginxZoneType is a helper map of string to AttributeNginxZoneType attribute value.
var MapAttributeNginxZoneType = map[string]AttributeNginxZoneType{
	"SERVER":   AttributeNginxZoneTypeSERVER,
	"LOCATION": AttributeNginxZoneTypeLOCATION,
}

type metricNginxCacheBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.cache.bytes metric with initial data.
func (m *metricNginxCacheBytes) init() {
	m.data.SetName("nginx.cache.bytes")
	m.data.SetDescription("The total number of bytes read from the cache or proxied server.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxCacheBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxCacheOutcomeAttributeValue string, nginxCacheNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.cache.outcome", nginxCacheOutcomeAttributeValue)
	dp.Attributes().PutStr("nginx.cache.name", nginxCacheNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxCacheBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxCacheBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxCacheBytes(cfg MetricConfig) metricNginxCacheBytes {
	m := metricNginxCacheBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxCacheMemoryLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.cache.memory.limit metric with initial data.
func (m *metricNginxCacheMemoryLimit) init() {
	m.data.SetName("nginx.cache.memory.limit")
	m.data.SetDescription("The limit on the maximum size of the cache specified in the configuration.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxCacheMemoryLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxCacheNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.cache.name", nginxCacheNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxCacheMemoryLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxCacheMemoryLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxCacheMemoryLimit(cfg MetricConfig) metricNginxCacheMemoryLimit {
	m := metricNginxCacheMemoryLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxCacheMemoryUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.cache.memory.usage metric with initial data.
func (m *metricNginxCacheMemoryUsage) init() {
	m.data.SetName("nginx.cache.memory.usage")
	m.data.SetDescription("The current size of the cache.")
	m.data.SetUnit("bytes")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxCacheMemoryUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxCacheNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.cache.name", nginxCacheNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxCacheMemoryUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxCacheMemoryUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxCacheMemoryUsage(cfg MetricConfig) metricNginxCacheMemoryUsage {
	m := metricNginxCacheMemoryUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxCacheResponses struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.cache.responses metric with initial data.
func (m *metricNginxCacheResponses) init() {
	m.data.SetName("nginx.cache.responses")
	m.data.SetDescription("The total number of responses read from the cache or proxied server.")
	m.data.SetUnit("responses")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxCacheResponses) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxCacheOutcomeAttributeValue string, nginxCacheNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.cache.outcome", nginxCacheOutcomeAttributeValue)
	dp.Attributes().PutStr("nginx.cache.name", nginxCacheNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxCacheResponses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxCacheResponses) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxCacheResponses(cfg MetricConfig) metricNginxCacheResponses {
	m := metricNginxCacheResponses{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxConfigReloads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.config.reloads metric with initial data.
func (m *metricNginxConfigReloads) init() {
	m.data.SetName("nginx.config.reloads")
	m.data.SetDescription("The total number of NGINX config reloads.")
	m.data.SetUnit("reloads")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNginxConfigReloads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxConfigReloads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxConfigReloads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxConfigReloads(cfg MetricConfig) metricNginxConfigReloads {
	m := metricNginxConfigReloads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPConn struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.conn metric with initial data.
func (m *metricNginxHTTPConn) init() {
	m.data.SetName("nginx.http.conn")
	m.data.SetDescription("The total number of connections.")
	m.data.SetUnit("connections")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPConn) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxConnOutcomeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.conn.outcome", nginxConnOutcomeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPConn) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPConn) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPConn(cfg MetricConfig) metricNginxHTTPConn {
	m := metricNginxHTTPConn{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPConnCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.conn.count metric with initial data.
func (m *metricNginxHTTPConnCount) init() {
	m.data.SetName("nginx.http.conn.count")
	m.data.SetDescription("The current number of connections.")
	m.data.SetUnit("connections")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPConnCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxConnOutcomeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.conn.outcome", nginxConnOutcomeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPConnCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPConnCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPConnCount(cfg MetricConfig) metricNginxHTTPConnCount {
	m := metricNginxHTTPConnCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPLimitConnRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.limit_conn.requests metric with initial data.
func (m *metricNginxHTTPLimitConnRequests) init() {
	m.data.SetName("nginx.http.limit_conn.requests")
	m.data.SetDescription("The total number of connections to an endpoint with a limit_conn directive.")
	m.data.SetUnit("connections")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPLimitConnRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxLimitConnOutcomeAttributeValue string, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.limit_conn.outcome", nginxLimitConnOutcomeAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPLimitConnRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPLimitConnRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPLimitConnRequests(cfg MetricConfig) metricNginxHTTPLimitConnRequests {
	m := metricNginxHTTPLimitConnRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPLimitReqRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.limit_req.requests metric with initial data.
func (m *metricNginxHTTPLimitReqRequests) init() {
	m.data.SetName("nginx.http.limit_req.requests")
	m.data.SetDescription("The total number of requests to an endpoint with a limit_req directive.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPLimitReqRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxLimitReqOutcomeAttributeValue string, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.limit_req.outcome", nginxLimitReqOutcomeAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPLimitReqRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPLimitReqRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPLimitReqRequests(cfg MetricConfig) metricNginxHTTPLimitReqRequests {
	m := metricNginxHTTPLimitReqRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPRequestByteIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.request.byte.io metric with initial data.
func (m *metricNginxHTTPRequestByteIo) init() {
	m.data.SetName("nginx.http.request.byte.io")
	m.data.SetDescription("The total number of HTTP byte IO.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPRequestByteIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue string, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.byte.io.direction", nginxByteIoDirectionAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPRequestByteIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPRequestByteIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPRequestByteIo(cfg MetricConfig) metricNginxHTTPRequestByteIo {
	m := metricNginxHTTPRequestByteIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPRequestDiscarded struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.request.discarded metric with initial data.
func (m *metricNginxHTTPRequestDiscarded) init() {
	m.data.SetName("nginx.http.request.discarded")
	m.data.SetDescription("The total number of requests completed without sending a response.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPRequestDiscarded) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPRequestDiscarded) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPRequestDiscarded) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPRequestDiscarded(cfg MetricConfig) metricNginxHTTPRequestDiscarded {
	m := metricNginxHTTPRequestDiscarded{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPRequestProcessingCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.request.processing.count metric with initial data.
func (m *metricNginxHTTPRequestProcessingCount) init() {
	m.data.SetName("nginx.http.request.processing.count")
	m.data.SetDescription("The number of client requests that are currently being processed.")
	m.data.SetUnit("requests")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPRequestProcessingCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPRequestProcessingCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPRequestProcessingCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPRequestProcessingCount(cfg MetricConfig) metricNginxHTTPRequestProcessingCount {
	m := metricNginxHTTPRequestProcessingCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.requests metric with initial data.
func (m *metricNginxHTTPRequests) init() {
	m.data.SetName("nginx.http.requests")
	m.data.SetDescription("The total number of client requests received from clients.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPRequests(cfg MetricConfig) metricNginxHTTPRequests {
	m := metricNginxHTTPRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPRequestsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.requests.count metric with initial data.
func (m *metricNginxHTTPRequestsCount) init() {
	m.data.SetName("nginx.http.requests.count")
	m.data.SetDescription("The current number of client requests received from clients.")
	m.data.SetUnit("requests")
	m.data.SetEmptyGauge()
}

func (m *metricNginxHTTPRequestsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPRequestsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPRequestsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPRequestsCount(cfg MetricConfig) metricNginxHTTPRequestsCount {
	m := metricNginxHTTPRequestsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPResponseStatus struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.response.status metric with initial data.
func (m *metricNginxHTTPResponseStatus) init() {
	m.data.SetName("nginx.http.response.status")
	m.data.SetDescription("The number of responses, grouped by status code range.")
	m.data.SetUnit("responses")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPResponseStatus) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue string, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.status_range", nginxStatusRangeAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPResponseStatus) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPResponseStatus) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPResponseStatus(cfg MetricConfig) metricNginxHTTPResponseStatus {
	m := metricNginxHTTPResponseStatus{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPResponses struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.responses metric with initial data.
func (m *metricNginxHTTPResponses) init() {
	m.data.SetName("nginx.http.responses")
	m.data.SetDescription("The total number of client requests received from clients.")
	m.data.SetUnit("responses")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPResponses) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.zone.type", nginxZoneTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPResponses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPResponses) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPResponses(cfg MetricConfig) metricNginxHTTPResponses {
	m := metricNginxHTTPResponses{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamKeepaliveCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.keepalive.count metric with initial data.
func (m *metricNginxHTTPUpstreamKeepaliveCount) init() {
	m.data.SetName("nginx.http.upstream.keepalive.count")
	m.data.SetDescription("The current number of idle keepalive connections per HTTP upstream.")
	m.data.SetUnit("connections")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamKeepaliveCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamKeepaliveCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamKeepaliveCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamKeepaliveCount(cfg MetricConfig) metricNginxHTTPUpstreamKeepaliveCount {
	m := metricNginxHTTPUpstreamKeepaliveCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerByteIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.byte.io metric with initial data.
func (m *metricNginxHTTPUpstreamPeerByteIo) init() {
	m.data.SetName("nginx.http.upstream.peer.byte.io")
	m.data.SetDescription("The total number of byte IO per HTTP upstream peer.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerByteIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.byte.io.direction", nginxByteIoDirectionAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerByteIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerByteIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerByteIo(cfg MetricConfig) metricNginxHTTPUpstreamPeerByteIo {
	m := metricNginxHTTPUpstreamPeerByteIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerConnCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.conn.count metric with initial data.
func (m *metricNginxHTTPUpstreamPeerConnCount) init() {
	m.data.SetName("nginx.http.upstream.peer.conn.count")
	m.data.SetDescription("The average number of active connections per HTTP upstream peer.")
	m.data.SetUnit("connections")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerConnCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerConnCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerConnCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerConnCount(cfg MetricConfig) metricNginxHTTPUpstreamPeerConnCount {
	m := metricNginxHTTPUpstreamPeerConnCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.count metric with initial data.
func (m *metricNginxHTTPUpstreamPeerCount) init() {
	m.data.SetName("nginx.http.upstream.peer.count")
	m.data.SetDescription("The current count of peers on the HTTP upstream grouped by state.")
	m.data.SetUnit("peers")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.peer.state", nginxPeerStateAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerCount(cfg MetricConfig) metricNginxHTTPUpstreamPeerCount {
	m := metricNginxHTTPUpstreamPeerCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerFails struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.fails metric with initial data.
func (m *metricNginxHTTPUpstreamPeerFails) init() {
	m.data.SetName("nginx.http.upstream.peer.fails")
	m.data.SetDescription("The total number of unsuccessful attempts to communicate with the HTTP upstream peer.")
	m.data.SetUnit("attempts")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerFails) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerFails) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerFails) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerFails(cfg MetricConfig) metricNginxHTTPUpstreamPeerFails {
	m := metricNginxHTTPUpstreamPeerFails{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerHeaderTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.header.time metric with initial data.
func (m *metricNginxHTTPUpstreamPeerHeaderTime) init() {
	m.data.SetName("nginx.http.upstream.peer.header.time")
	m.data.SetDescription("The average time to get the response header from the HTTP upstream peer.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerHeaderTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerHeaderTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerHeaderTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerHeaderTime(cfg MetricConfig) metricNginxHTTPUpstreamPeerHeaderTime {
	m := metricNginxHTTPUpstreamPeerHeaderTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerHealthChecks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.health_checks metric with initial data.
func (m *metricNginxHTTPUpstreamPeerHealthChecks) init() {
	m.data.SetName("nginx.http.upstream.peer.health_checks")
	m.data.SetDescription("The total number of health check requests made to a HTTP upstream peer.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerHealthChecks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxHealthCheckAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.health_check", nginxHealthCheckAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerHealthChecks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerHealthChecks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerHealthChecks(cfg MetricConfig) metricNginxHTTPUpstreamPeerHealthChecks {
	m := metricNginxHTTPUpstreamPeerHealthChecks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.requests metric with initial data.
func (m *metricNginxHTTPUpstreamPeerRequests) init() {
	m.data.SetName("nginx.http.upstream.peer.requests")
	m.data.SetDescription("The total number of client requests forwarded to the HTTP upstream peer.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerRequests(cfg MetricConfig) metricNginxHTTPUpstreamPeerRequests {
	m := metricNginxHTTPUpstreamPeerRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerResponseTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.response.time metric with initial data.
func (m *metricNginxHTTPUpstreamPeerResponseTime) init() {
	m.data.SetName("nginx.http.upstream.peer.response.time")
	m.data.SetDescription("The average time to get the full response from the HTTP upstream peer.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerResponseTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerResponseTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerResponseTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerResponseTime(cfg MetricConfig) metricNginxHTTPUpstreamPeerResponseTime {
	m := metricNginxHTTPUpstreamPeerResponseTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerResponses struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.responses metric with initial data.
func (m *metricNginxHTTPUpstreamPeerResponses) init() {
	m.data.SetName("nginx.http.upstream.peer.responses")
	m.data.SetDescription("The total number of responses obtained from the HTTP upstream peer grouped by status range.")
	m.data.SetUnit("responses")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerResponses) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.status_range", nginxStatusRangeAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerResponses) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerResponses) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerResponses(cfg MetricConfig) metricNginxHTTPUpstreamPeerResponses {
	m := metricNginxHTTPUpstreamPeerResponses{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerState struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.state metric with initial data.
func (m *metricNginxHTTPUpstreamPeerState) init() {
	m.data.SetName("nginx.http.upstream.peer.state")
	m.data.SetDescription("Current state of an upstream peer in deployment.")
	m.data.SetUnit("is_deployed")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerState) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.peer.state", nginxPeerStateAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerState) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerState) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerState(cfg MetricConfig) metricNginxHTTPUpstreamPeerState {
	m := metricNginxHTTPUpstreamPeerState{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamPeerUnavailables struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.peer.unavailables metric with initial data.
func (m *metricNginxHTTPUpstreamPeerUnavailables) init() {
	m.data.SetName("nginx.http.upstream.peer.unavailables")
	m.data.SetDescription("Number of times the server became unavailable for client requests (unavail).")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamPeerUnavailables) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamPeerUnavailables) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamPeerUnavailables) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamPeerUnavailables(cfg MetricConfig) metricNginxHTTPUpstreamPeerUnavailables {
	m := metricNginxHTTPUpstreamPeerUnavailables{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamQueueLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.queue.limit metric with initial data.
func (m *metricNginxHTTPUpstreamQueueLimit) init() {
	m.data.SetName("nginx.http.upstream.queue.limit")
	m.data.SetDescription("The maximum number of requests that can be in the queue at the same time.")
	m.data.SetUnit("requests")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamQueueLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamQueueLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamQueueLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamQueueLimit(cfg MetricConfig) metricNginxHTTPUpstreamQueueLimit {
	m := metricNginxHTTPUpstreamQueueLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamQueueOverflows struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.queue.overflows metric with initial data.
func (m *metricNginxHTTPUpstreamQueueOverflows) init() {
	m.data.SetName("nginx.http.upstream.queue.overflows")
	m.data.SetDescription("The total number of requests rejected due to the queue overflow.")
	m.data.SetUnit("responses")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamQueueOverflows) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamQueueOverflows) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamQueueOverflows) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamQueueOverflows(cfg MetricConfig) metricNginxHTTPUpstreamQueueOverflows {
	m := metricNginxHTTPUpstreamQueueOverflows{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamQueueUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.queue.usage metric with initial data.
func (m *metricNginxHTTPUpstreamQueueUsage) init() {
	m.data.SetName("nginx.http.upstream.queue.usage")
	m.data.SetDescription("The current number of requests in the queue.")
	m.data.SetUnit("requests")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamQueueUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamQueueUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamQueueUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamQueueUsage(cfg MetricConfig) metricNginxHTTPUpstreamQueueUsage {
	m := metricNginxHTTPUpstreamQueueUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxHTTPUpstreamZombieCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.http.upstream.zombie.count metric with initial data.
func (m *metricNginxHTTPUpstreamZombieCount) init() {
	m.data.SetName("nginx.http.upstream.zombie.count")
	m.data.SetDescription("The current number of upstream peers removed from the group but still processing active client requests.")
	m.data.SetUnit("is_deployed")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxHTTPUpstreamZombieCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxHTTPUpstreamZombieCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxHTTPUpstreamZombieCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxHTTPUpstreamZombieCount(cfg MetricConfig) metricNginxHTTPUpstreamZombieCount {
	m := metricNginxHTTPUpstreamZombieCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabPageFree struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.page.free metric with initial data.
func (m *metricNginxSlabPageFree) init() {
	m.data.SetName("nginx.slab.page.free")
	m.data.SetDescription("The current number of free memory pages.")
	m.data.SetUnit("pages")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabPageFree) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabPageFree) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabPageFree) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabPageFree(cfg MetricConfig) metricNginxSlabPageFree {
	m := metricNginxSlabPageFree{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabPageLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.page.limit metric with initial data.
func (m *metricNginxSlabPageLimit) init() {
	m.data.SetName("nginx.slab.page.limit")
	m.data.SetDescription("The total number of memory pages (free and used).")
	m.data.SetUnit("pages")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabPageLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabPageLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabPageLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabPageLimit(cfg MetricConfig) metricNginxSlabPageLimit {
	m := metricNginxSlabPageLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabPageUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.page.usage metric with initial data.
func (m *metricNginxSlabPageUsage) init() {
	m.data.SetName("nginx.slab.page.usage")
	m.data.SetDescription("The current number of used memory pages.")
	m.data.SetUnit("pages")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabPageUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabPageUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabPageUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabPageUsage(cfg MetricConfig) metricNginxSlabPageUsage {
	m := metricNginxSlabPageUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabPageUtilization struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.page.utilization metric with initial data.
func (m *metricNginxSlabPageUtilization) init() {
	m.data.SetName("nginx.slab.page.utilization")
	m.data.SetDescription("The current percentage of used memory pages.")
	m.data.SetUnit("pages")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabPageUtilization) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabPageUtilization) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabPageUtilization) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabPageUtilization(cfg MetricConfig) metricNginxSlabPageUtilization {
	m := metricNginxSlabPageUtilization{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabSlotAllocations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.slot.allocations metric with initial data.
func (m *metricNginxSlabSlotAllocations) init() {
	m.data.SetName("nginx.slab.slot.allocations")
	m.data.SetDescription("The number of attempts to allocate memory of specified size.")
	m.data.SetUnit("allocations")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabSlotAllocations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxSlabSlotAllocationResultAttributeValue string, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("nginx.slab.slot.limit", nginxSlabSlotLimitAttributeValue)
	dp.Attributes().PutStr("nginx.slab.slot.allocation.result", nginxSlabSlotAllocationResultAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabSlotAllocations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabSlotAllocations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabSlotAllocations(cfg MetricConfig) metricNginxSlabSlotAllocations {
	m := metricNginxSlabSlotAllocations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabSlotFree struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.slot.free metric with initial data.
func (m *metricNginxSlabSlotFree) init() {
	m.data.SetName("nginx.slab.slot.free")
	m.data.SetDescription("The current number of free memory slots.")
	m.data.SetUnit("slots")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabSlotFree) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("nginx.slab.slot.limit", nginxSlabSlotLimitAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabSlotFree) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabSlotFree) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabSlotFree(cfg MetricConfig) metricNginxSlabSlotFree {
	m := metricNginxSlabSlotFree{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSlabSlotUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.slab.slot.usage metric with initial data.
func (m *metricNginxSlabSlotUsage) init() {
	m.data.SetName("nginx.slab.slot.usage")
	m.data.SetDescription("The current number of used memory slots.")
	m.data.SetUnit("slots")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSlabSlotUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutInt("nginx.slab.slot.limit", nginxSlabSlotLimitAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSlabSlotUsage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSlabSlotUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSlabSlotUsage(cfg MetricConfig) metricNginxSlabSlotUsage {
	m := metricNginxSlabSlotUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSslCertificateVerifyFailures struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.ssl.certificate.verify_failures metric with initial data.
func (m *metricNginxSslCertificateVerifyFailures) init() {
	m.data.SetName("nginx.ssl.certificate.verify_failures")
	m.data.SetDescription("The total number of SSL certificate verification failures.")
	m.data.SetUnit("certificates")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSslCertificateVerifyFailures) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxSslVerifyFailureReasonAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.ssl.verify_failure.reason", nginxSslVerifyFailureReasonAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSslCertificateVerifyFailures) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSslCertificateVerifyFailures) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSslCertificateVerifyFailures(cfg MetricConfig) metricNginxSslCertificateVerifyFailures {
	m := metricNginxSslCertificateVerifyFailures{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxSslHandshakes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.ssl.handshakes metric with initial data.
func (m *metricNginxSslHandshakes) init() {
	m.data.SetName("nginx.ssl.handshakes")
	m.data.SetDescription("The total number of SSL handshakes.")
	m.data.SetUnit("handshakes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxSslHandshakes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxSslStatusAttributeValue string, nginxSslHandshakeReasonAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.ssl.status", nginxSslStatusAttributeValue)
	dp.Attributes().PutStr("nginx.ssl.handshake.reason", nginxSslHandshakeReasonAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxSslHandshakes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxSslHandshakes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxSslHandshakes(cfg MetricConfig) metricNginxSslHandshakes {
	m := metricNginxSslHandshakes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamByteIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.byte.io metric with initial data.
func (m *metricNginxStreamByteIo) init() {
	m.data.SetName("nginx.stream.byte.io")
	m.data.SetDescription("The total number of Stream byte IO.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamByteIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue string, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.byte.io.direction", nginxByteIoDirectionAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamByteIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamByteIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamByteIo(cfg MetricConfig) metricNginxStreamByteIo {
	m := metricNginxStreamByteIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamConnectionAccepted struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.connection.accepted metric with initial data.
func (m *metricNginxStreamConnectionAccepted) init() {
	m.data.SetName("nginx.stream.connection.accepted")
	m.data.SetDescription("The total number of connections accepted from clients.")
	m.data.SetUnit("connections")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamConnectionAccepted) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamConnectionAccepted) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamConnectionAccepted) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamConnectionAccepted(cfg MetricConfig) metricNginxStreamConnectionAccepted {
	m := metricNginxStreamConnectionAccepted{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamConnectionDiscarded struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.connection.discarded metric with initial data.
func (m *metricNginxStreamConnectionDiscarded) init() {
	m.data.SetName("nginx.stream.connection.discarded")
	m.data.SetDescription("Total number of connections completed without creating a session.")
	m.data.SetUnit("connections")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamConnectionDiscarded) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamConnectionDiscarded) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamConnectionDiscarded) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamConnectionDiscarded(cfg MetricConfig) metricNginxStreamConnectionDiscarded {
	m := metricNginxStreamConnectionDiscarded{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamConnectionProcessingCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.connection.processing.count metric with initial data.
func (m *metricNginxStreamConnectionProcessingCount) init() {
	m.data.SetName("nginx.stream.connection.processing.count")
	m.data.SetDescription("The number of client connections that are currently being processed.")
	m.data.SetUnit("connections")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamConnectionProcessingCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamConnectionProcessingCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamConnectionProcessingCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamConnectionProcessingCount(cfg MetricConfig) metricNginxStreamConnectionProcessingCount {
	m := metricNginxStreamConnectionProcessingCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamSessionStatus struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.session.status metric with initial data.
func (m *metricNginxStreamSessionStatus) init() {
	m.data.SetName("nginx.stream.session.status")
	m.data.SetDescription("The total number of completed sessions.")
	m.data.SetUnit("sessions")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamSessionStatus) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue string, nginxZoneNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.status_range", nginxStatusRangeAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamSessionStatus) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamSessionStatus) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamSessionStatus(cfg MetricConfig) metricNginxStreamSessionStatus {
	m := metricNginxStreamSessionStatus{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerByteIo struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.byte.io metric with initial data.
func (m *metricNginxStreamUpstreamPeerByteIo) init() {
	m.data.SetName("nginx.stream.upstream.peer.byte.io")
	m.data.SetDescription("The total number of Stream Upstream Peer byte IO.")
	m.data.SetUnit("bytes")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerByteIo) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.byte.io.direction", nginxByteIoDirectionAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerByteIo) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerByteIo) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerByteIo(cfg MetricConfig) metricNginxStreamUpstreamPeerByteIo {
	m := metricNginxStreamUpstreamPeerByteIo{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerConnCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.conn.count metric with initial data.
func (m *metricNginxStreamUpstreamPeerConnCount) init() {
	m.data.SetName("nginx.stream.upstream.peer.conn.count")
	m.data.SetDescription("The current number of Stream Upstream Peer connections.")
	m.data.SetUnit("connections")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerConnCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerConnCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerConnCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerConnCount(cfg MetricConfig) metricNginxStreamUpstreamPeerConnCount {
	m := metricNginxStreamUpstreamPeerConnCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerConnTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.conn.time metric with initial data.
func (m *metricNginxStreamUpstreamPeerConnTime) init() {
	m.data.SetName("nginx.stream.upstream.peer.conn.time")
	m.data.SetDescription("The average time to connect to the stream upstream peer.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerConnTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerConnTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerConnTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerConnTime(cfg MetricConfig) metricNginxStreamUpstreamPeerConnTime {
	m := metricNginxStreamUpstreamPeerConnTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerConns struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.conns metric with initial data.
func (m *metricNginxStreamUpstreamPeerConns) init() {
	m.data.SetName("nginx.stream.upstream.peer.conns")
	m.data.SetDescription("The total number of client connections forwarded to this stream upstream peer.")
	m.data.SetUnit("connections")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerConns) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerConns) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerConns) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerConns(cfg MetricConfig) metricNginxStreamUpstreamPeerConns {
	m := metricNginxStreamUpstreamPeerConns{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.count metric with initial data.
func (m *metricNginxStreamUpstreamPeerCount) init() {
	m.data.SetName("nginx.stream.upstream.peer.count")
	m.data.SetDescription("The total number of stream upstream peers grouped by state.")
	m.data.SetUnit("peers")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.peer.state", nginxPeerStateAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerCount(cfg MetricConfig) metricNginxStreamUpstreamPeerCount {
	m := metricNginxStreamUpstreamPeerCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerFails struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.fails metric with initial data.
func (m *metricNginxStreamUpstreamPeerFails) init() {
	m.data.SetName("nginx.stream.upstream.peer.fails")
	m.data.SetDescription("The total number of unsuccessful attempts to communicate with the stream upstream peer.")
	m.data.SetUnit("peers")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerFails) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerFails) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerFails) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerFails(cfg MetricConfig) metricNginxStreamUpstreamPeerFails {
	m := metricNginxStreamUpstreamPeerFails{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerHealthChecks struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.health_checks metric with initial data.
func (m *metricNginxStreamUpstreamPeerHealthChecks) init() {
	m.data.SetName("nginx.stream.upstream.peer.health_checks")
	m.data.SetDescription("The total number of health check requests made to the stream upstream peer.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerHealthChecks) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxHealthCheckAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.health_check", nginxHealthCheckAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerHealthChecks) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerHealthChecks) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerHealthChecks(cfg MetricConfig) metricNginxStreamUpstreamPeerHealthChecks {
	m := metricNginxStreamUpstreamPeerHealthChecks{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerResponseTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.response.time metric with initial data.
func (m *metricNginxStreamUpstreamPeerResponseTime) init() {
	m.data.SetName("nginx.stream.upstream.peer.response.time")
	m.data.SetDescription("The average time to receive the last byte of data for the stream upstream peer.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerResponseTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerResponseTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerResponseTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerResponseTime(cfg MetricConfig) metricNginxStreamUpstreamPeerResponseTime {
	m := metricNginxStreamUpstreamPeerResponseTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerState struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.state metric with initial data.
func (m *metricNginxStreamUpstreamPeerState) init() {
	m.data.SetName("nginx.stream.upstream.peer.state")
	m.data.SetDescription("Current state of upstream peers in deployment. If any of the upstream peers in the deployment match the given state then the value will be 1. If no upstream peer is a match then the value will be 0.")
	m.data.SetUnit("deployments")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerState) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue string, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.peer.state", nginxPeerStateAttributeValue)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerState) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerState) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerState(cfg MetricConfig) metricNginxStreamUpstreamPeerState {
	m := metricNginxStreamUpstreamPeerState{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerTtfbTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.ttfb.time metric with initial data.
func (m *metricNginxStreamUpstreamPeerTtfbTime) init() {
	m.data.SetName("nginx.stream.upstream.peer.ttfb.time")
	m.data.SetDescription("The average time to receive the first byte of data for the stream upstream peer.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerTtfbTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerTtfbTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerTtfbTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerTtfbTime(cfg MetricConfig) metricNginxStreamUpstreamPeerTtfbTime {
	m := metricNginxStreamUpstreamPeerTtfbTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamPeerUnavailable struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.peer.unavailable metric with initial data.
func (m *metricNginxStreamUpstreamPeerUnavailable) init() {
	m.data.SetName("nginx.stream.upstream.peer.unavailable")
	m.data.SetDescription("How many times the server became unavailable for client connections (state unavail) due to the number of unsuccessful attempts reaching the max_fails threshold.")
	m.data.SetUnit("requests")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamPeerUnavailable) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
	dp.Attributes().PutStr("nginx.peer.address", nginxPeerAddressAttributeValue)
	dp.Attributes().PutStr("nginx.peer.name", nginxPeerNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamPeerUnavailable) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamPeerUnavailable) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamPeerUnavailable(cfg MetricConfig) metricNginxStreamUpstreamPeerUnavailable {
	m := metricNginxStreamUpstreamPeerUnavailable{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNginxStreamUpstreamZombieCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills nginx.stream.upstream.zombie.count metric with initial data.
func (m *metricNginxStreamUpstreamZombieCount) init() {
	m.data.SetName("nginx.stream.upstream.zombie.count")
	m.data.SetDescription("The current number of peers removed from the group but still processing active client connections.")
	m.data.SetUnit("deployments")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNginxStreamUpstreamZombieCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("nginx.zone.name", nginxZoneNameAttributeValue)
	dp.Attributes().PutStr("nginx.upstream.name", nginxUpstreamNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNginxStreamUpstreamZombieCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNginxStreamUpstreamZombieCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNginxStreamUpstreamZombieCount(cfg MetricConfig) metricNginxStreamUpstreamZombieCount {
	m := metricNginxStreamUpstreamZombieCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                     MetricsBuilderConfig // config of the metrics builder.
	startTime                                  pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                            int                  // maximum observed number of metrics per resource.
	metricsBuffer                              pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                  component.BuildInfo  // contains version information.
	metricNginxCacheBytes                      metricNginxCacheBytes
	metricNginxCacheMemoryLimit                metricNginxCacheMemoryLimit
	metricNginxCacheMemoryUsage                metricNginxCacheMemoryUsage
	metricNginxCacheResponses                  metricNginxCacheResponses
	metricNginxConfigReloads                   metricNginxConfigReloads
	metricNginxHTTPConn                        metricNginxHTTPConn
	metricNginxHTTPConnCount                   metricNginxHTTPConnCount
	metricNginxHTTPLimitConnRequests           metricNginxHTTPLimitConnRequests
	metricNginxHTTPLimitReqRequests            metricNginxHTTPLimitReqRequests
	metricNginxHTTPRequestByteIo               metricNginxHTTPRequestByteIo
	metricNginxHTTPRequestDiscarded            metricNginxHTTPRequestDiscarded
	metricNginxHTTPRequestProcessingCount      metricNginxHTTPRequestProcessingCount
	metricNginxHTTPRequests                    metricNginxHTTPRequests
	metricNginxHTTPRequestsCount               metricNginxHTTPRequestsCount
	metricNginxHTTPResponseStatus              metricNginxHTTPResponseStatus
	metricNginxHTTPResponses                   metricNginxHTTPResponses
	metricNginxHTTPUpstreamKeepaliveCount      metricNginxHTTPUpstreamKeepaliveCount
	metricNginxHTTPUpstreamPeerByteIo          metricNginxHTTPUpstreamPeerByteIo
	metricNginxHTTPUpstreamPeerConnCount       metricNginxHTTPUpstreamPeerConnCount
	metricNginxHTTPUpstreamPeerCount           metricNginxHTTPUpstreamPeerCount
	metricNginxHTTPUpstreamPeerFails           metricNginxHTTPUpstreamPeerFails
	metricNginxHTTPUpstreamPeerHeaderTime      metricNginxHTTPUpstreamPeerHeaderTime
	metricNginxHTTPUpstreamPeerHealthChecks    metricNginxHTTPUpstreamPeerHealthChecks
	metricNginxHTTPUpstreamPeerRequests        metricNginxHTTPUpstreamPeerRequests
	metricNginxHTTPUpstreamPeerResponseTime    metricNginxHTTPUpstreamPeerResponseTime
	metricNginxHTTPUpstreamPeerResponses       metricNginxHTTPUpstreamPeerResponses
	metricNginxHTTPUpstreamPeerState           metricNginxHTTPUpstreamPeerState
	metricNginxHTTPUpstreamPeerUnavailables    metricNginxHTTPUpstreamPeerUnavailables
	metricNginxHTTPUpstreamQueueLimit          metricNginxHTTPUpstreamQueueLimit
	metricNginxHTTPUpstreamQueueOverflows      metricNginxHTTPUpstreamQueueOverflows
	metricNginxHTTPUpstreamQueueUsage          metricNginxHTTPUpstreamQueueUsage
	metricNginxHTTPUpstreamZombieCount         metricNginxHTTPUpstreamZombieCount
	metricNginxSlabPageFree                    metricNginxSlabPageFree
	metricNginxSlabPageLimit                   metricNginxSlabPageLimit
	metricNginxSlabPageUsage                   metricNginxSlabPageUsage
	metricNginxSlabPageUtilization             metricNginxSlabPageUtilization
	metricNginxSlabSlotAllocations             metricNginxSlabSlotAllocations
	metricNginxSlabSlotFree                    metricNginxSlabSlotFree
	metricNginxSlabSlotUsage                   metricNginxSlabSlotUsage
	metricNginxSslCertificateVerifyFailures    metricNginxSslCertificateVerifyFailures
	metricNginxSslHandshakes                   metricNginxSslHandshakes
	metricNginxStreamByteIo                    metricNginxStreamByteIo
	metricNginxStreamConnectionAccepted        metricNginxStreamConnectionAccepted
	metricNginxStreamConnectionDiscarded       metricNginxStreamConnectionDiscarded
	metricNginxStreamConnectionProcessingCount metricNginxStreamConnectionProcessingCount
	metricNginxStreamSessionStatus             metricNginxStreamSessionStatus
	metricNginxStreamUpstreamPeerByteIo        metricNginxStreamUpstreamPeerByteIo
	metricNginxStreamUpstreamPeerConnCount     metricNginxStreamUpstreamPeerConnCount
	metricNginxStreamUpstreamPeerConnTime      metricNginxStreamUpstreamPeerConnTime
	metricNginxStreamUpstreamPeerConns         metricNginxStreamUpstreamPeerConns
	metricNginxStreamUpstreamPeerCount         metricNginxStreamUpstreamPeerCount
	metricNginxStreamUpstreamPeerFails         metricNginxStreamUpstreamPeerFails
	metricNginxStreamUpstreamPeerHealthChecks  metricNginxStreamUpstreamPeerHealthChecks
	metricNginxStreamUpstreamPeerResponseTime  metricNginxStreamUpstreamPeerResponseTime
	metricNginxStreamUpstreamPeerState         metricNginxStreamUpstreamPeerState
	metricNginxStreamUpstreamPeerTtfbTime      metricNginxStreamUpstreamPeerTtfbTime
	metricNginxStreamUpstreamPeerUnavailable   metricNginxStreamUpstreamPeerUnavailable
	metricNginxStreamUpstreamZombieCount       metricNginxStreamUpstreamZombieCount
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}

func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                     mbc,
		startTime:                                  pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                              pmetric.NewMetrics(),
		buildInfo:                                  settings.BuildInfo,
		metricNginxCacheBytes:                      newMetricNginxCacheBytes(mbc.Metrics.NginxCacheBytes),
		metricNginxCacheMemoryLimit:                newMetricNginxCacheMemoryLimit(mbc.Metrics.NginxCacheMemoryLimit),
		metricNginxCacheMemoryUsage:                newMetricNginxCacheMemoryUsage(mbc.Metrics.NginxCacheMemoryUsage),
		metricNginxCacheResponses:                  newMetricNginxCacheResponses(mbc.Metrics.NginxCacheResponses),
		metricNginxConfigReloads:                   newMetricNginxConfigReloads(mbc.Metrics.NginxConfigReloads),
		metricNginxHTTPConn:                        newMetricNginxHTTPConn(mbc.Metrics.NginxHTTPConn),
		metricNginxHTTPConnCount:                   newMetricNginxHTTPConnCount(mbc.Metrics.NginxHTTPConnCount),
		metricNginxHTTPLimitConnRequests:           newMetricNginxHTTPLimitConnRequests(mbc.Metrics.NginxHTTPLimitConnRequests),
		metricNginxHTTPLimitReqRequests:            newMetricNginxHTTPLimitReqRequests(mbc.Metrics.NginxHTTPLimitReqRequests),
		metricNginxHTTPRequestByteIo:               newMetricNginxHTTPRequestByteIo(mbc.Metrics.NginxHTTPRequestByteIo),
		metricNginxHTTPRequestDiscarded:            newMetricNginxHTTPRequestDiscarded(mbc.Metrics.NginxHTTPRequestDiscarded),
		metricNginxHTTPRequestProcessingCount:      newMetricNginxHTTPRequestProcessingCount(mbc.Metrics.NginxHTTPRequestProcessingCount),
		metricNginxHTTPRequests:                    newMetricNginxHTTPRequests(mbc.Metrics.NginxHTTPRequests),
		metricNginxHTTPRequestsCount:               newMetricNginxHTTPRequestsCount(mbc.Metrics.NginxHTTPRequestsCount),
		metricNginxHTTPResponseStatus:              newMetricNginxHTTPResponseStatus(mbc.Metrics.NginxHTTPResponseStatus),
		metricNginxHTTPResponses:                   newMetricNginxHTTPResponses(mbc.Metrics.NginxHTTPResponses),
		metricNginxHTTPUpstreamKeepaliveCount:      newMetricNginxHTTPUpstreamKeepaliveCount(mbc.Metrics.NginxHTTPUpstreamKeepaliveCount),
		metricNginxHTTPUpstreamPeerByteIo:          newMetricNginxHTTPUpstreamPeerByteIo(mbc.Metrics.NginxHTTPUpstreamPeerByteIo),
		metricNginxHTTPUpstreamPeerConnCount:       newMetricNginxHTTPUpstreamPeerConnCount(mbc.Metrics.NginxHTTPUpstreamPeerConnCount),
		metricNginxHTTPUpstreamPeerCount:           newMetricNginxHTTPUpstreamPeerCount(mbc.Metrics.NginxHTTPUpstreamPeerCount),
		metricNginxHTTPUpstreamPeerFails:           newMetricNginxHTTPUpstreamPeerFails(mbc.Metrics.NginxHTTPUpstreamPeerFails),
		metricNginxHTTPUpstreamPeerHeaderTime:      newMetricNginxHTTPUpstreamPeerHeaderTime(mbc.Metrics.NginxHTTPUpstreamPeerHeaderTime),
		metricNginxHTTPUpstreamPeerHealthChecks:    newMetricNginxHTTPUpstreamPeerHealthChecks(mbc.Metrics.NginxHTTPUpstreamPeerHealthChecks),
		metricNginxHTTPUpstreamPeerRequests:        newMetricNginxHTTPUpstreamPeerRequests(mbc.Metrics.NginxHTTPUpstreamPeerRequests),
		metricNginxHTTPUpstreamPeerResponseTime:    newMetricNginxHTTPUpstreamPeerResponseTime(mbc.Metrics.NginxHTTPUpstreamPeerResponseTime),
		metricNginxHTTPUpstreamPeerResponses:       newMetricNginxHTTPUpstreamPeerResponses(mbc.Metrics.NginxHTTPUpstreamPeerResponses),
		metricNginxHTTPUpstreamPeerState:           newMetricNginxHTTPUpstreamPeerState(mbc.Metrics.NginxHTTPUpstreamPeerState),
		metricNginxHTTPUpstreamPeerUnavailables:    newMetricNginxHTTPUpstreamPeerUnavailables(mbc.Metrics.NginxHTTPUpstreamPeerUnavailables),
		metricNginxHTTPUpstreamQueueLimit:          newMetricNginxHTTPUpstreamQueueLimit(mbc.Metrics.NginxHTTPUpstreamQueueLimit),
		metricNginxHTTPUpstreamQueueOverflows:      newMetricNginxHTTPUpstreamQueueOverflows(mbc.Metrics.NginxHTTPUpstreamQueueOverflows),
		metricNginxHTTPUpstreamQueueUsage:          newMetricNginxHTTPUpstreamQueueUsage(mbc.Metrics.NginxHTTPUpstreamQueueUsage),
		metricNginxHTTPUpstreamZombieCount:         newMetricNginxHTTPUpstreamZombieCount(mbc.Metrics.NginxHTTPUpstreamZombieCount),
		metricNginxSlabPageFree:                    newMetricNginxSlabPageFree(mbc.Metrics.NginxSlabPageFree),
		metricNginxSlabPageLimit:                   newMetricNginxSlabPageLimit(mbc.Metrics.NginxSlabPageLimit),
		metricNginxSlabPageUsage:                   newMetricNginxSlabPageUsage(mbc.Metrics.NginxSlabPageUsage),
		metricNginxSlabPageUtilization:             newMetricNginxSlabPageUtilization(mbc.Metrics.NginxSlabPageUtilization),
		metricNginxSlabSlotAllocations:             newMetricNginxSlabSlotAllocations(mbc.Metrics.NginxSlabSlotAllocations),
		metricNginxSlabSlotFree:                    newMetricNginxSlabSlotFree(mbc.Metrics.NginxSlabSlotFree),
		metricNginxSlabSlotUsage:                   newMetricNginxSlabSlotUsage(mbc.Metrics.NginxSlabSlotUsage),
		metricNginxSslCertificateVerifyFailures:    newMetricNginxSslCertificateVerifyFailures(mbc.Metrics.NginxSslCertificateVerifyFailures),
		metricNginxSslHandshakes:                   newMetricNginxSslHandshakes(mbc.Metrics.NginxSslHandshakes),
		metricNginxStreamByteIo:                    newMetricNginxStreamByteIo(mbc.Metrics.NginxStreamByteIo),
		metricNginxStreamConnectionAccepted:        newMetricNginxStreamConnectionAccepted(mbc.Metrics.NginxStreamConnectionAccepted),
		metricNginxStreamConnectionDiscarded:       newMetricNginxStreamConnectionDiscarded(mbc.Metrics.NginxStreamConnectionDiscarded),
		metricNginxStreamConnectionProcessingCount: newMetricNginxStreamConnectionProcessingCount(mbc.Metrics.NginxStreamConnectionProcessingCount),
		metricNginxStreamSessionStatus:             newMetricNginxStreamSessionStatus(mbc.Metrics.NginxStreamSessionStatus),
		metricNginxStreamUpstreamPeerByteIo:        newMetricNginxStreamUpstreamPeerByteIo(mbc.Metrics.NginxStreamUpstreamPeerByteIo),
		metricNginxStreamUpstreamPeerConnCount:     newMetricNginxStreamUpstreamPeerConnCount(mbc.Metrics.NginxStreamUpstreamPeerConnCount),
		metricNginxStreamUpstreamPeerConnTime:      newMetricNginxStreamUpstreamPeerConnTime(mbc.Metrics.NginxStreamUpstreamPeerConnTime),
		metricNginxStreamUpstreamPeerConns:         newMetricNginxStreamUpstreamPeerConns(mbc.Metrics.NginxStreamUpstreamPeerConns),
		metricNginxStreamUpstreamPeerCount:         newMetricNginxStreamUpstreamPeerCount(mbc.Metrics.NginxStreamUpstreamPeerCount),
		metricNginxStreamUpstreamPeerFails:         newMetricNginxStreamUpstreamPeerFails(mbc.Metrics.NginxStreamUpstreamPeerFails),
		metricNginxStreamUpstreamPeerHealthChecks:  newMetricNginxStreamUpstreamPeerHealthChecks(mbc.Metrics.NginxStreamUpstreamPeerHealthChecks),
		metricNginxStreamUpstreamPeerResponseTime:  newMetricNginxStreamUpstreamPeerResponseTime(mbc.Metrics.NginxStreamUpstreamPeerResponseTime),
		metricNginxStreamUpstreamPeerState:         newMetricNginxStreamUpstreamPeerState(mbc.Metrics.NginxStreamUpstreamPeerState),
		metricNginxStreamUpstreamPeerTtfbTime:      newMetricNginxStreamUpstreamPeerTtfbTime(mbc.Metrics.NginxStreamUpstreamPeerTtfbTime),
		metricNginxStreamUpstreamPeerUnavailable:   newMetricNginxStreamUpstreamPeerUnavailable(mbc.Metrics.NginxStreamUpstreamPeerUnavailable),
		metricNginxStreamUpstreamZombieCount:       newMetricNginxStreamUpstreamZombieCount(mbc.Metrics.NginxStreamUpstreamZombieCount),
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName("otelcol/nginxplusreceiver")
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricNginxCacheBytes.emit(ils.Metrics())
	mb.metricNginxCacheMemoryLimit.emit(ils.Metrics())
	mb.metricNginxCacheMemoryUsage.emit(ils.Metrics())
	mb.metricNginxCacheResponses.emit(ils.Metrics())
	mb.metricNginxConfigReloads.emit(ils.Metrics())
	mb.metricNginxHTTPConn.emit(ils.Metrics())
	mb.metricNginxHTTPConnCount.emit(ils.Metrics())
	mb.metricNginxHTTPLimitConnRequests.emit(ils.Metrics())
	mb.metricNginxHTTPLimitReqRequests.emit(ils.Metrics())
	mb.metricNginxHTTPRequestByteIo.emit(ils.Metrics())
	mb.metricNginxHTTPRequestDiscarded.emit(ils.Metrics())
	mb.metricNginxHTTPRequestProcessingCount.emit(ils.Metrics())
	mb.metricNginxHTTPRequests.emit(ils.Metrics())
	mb.metricNginxHTTPRequestsCount.emit(ils.Metrics())
	mb.metricNginxHTTPResponseStatus.emit(ils.Metrics())
	mb.metricNginxHTTPResponses.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamKeepaliveCount.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerByteIo.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerConnCount.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerCount.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerFails.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerHeaderTime.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerHealthChecks.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerRequests.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerResponseTime.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerResponses.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerState.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamPeerUnavailables.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamQueueLimit.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamQueueOverflows.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamQueueUsage.emit(ils.Metrics())
	mb.metricNginxHTTPUpstreamZombieCount.emit(ils.Metrics())
	mb.metricNginxSlabPageFree.emit(ils.Metrics())
	mb.metricNginxSlabPageLimit.emit(ils.Metrics())
	mb.metricNginxSlabPageUsage.emit(ils.Metrics())
	mb.metricNginxSlabPageUtilization.emit(ils.Metrics())
	mb.metricNginxSlabSlotAllocations.emit(ils.Metrics())
	mb.metricNginxSlabSlotFree.emit(ils.Metrics())
	mb.metricNginxSlabSlotUsage.emit(ils.Metrics())
	mb.metricNginxSslCertificateVerifyFailures.emit(ils.Metrics())
	mb.metricNginxSslHandshakes.emit(ils.Metrics())
	mb.metricNginxStreamByteIo.emit(ils.Metrics())
	mb.metricNginxStreamConnectionAccepted.emit(ils.Metrics())
	mb.metricNginxStreamConnectionDiscarded.emit(ils.Metrics())
	mb.metricNginxStreamConnectionProcessingCount.emit(ils.Metrics())
	mb.metricNginxStreamSessionStatus.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerByteIo.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerConnCount.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerConnTime.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerConns.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerCount.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerFails.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerHealthChecks.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerResponseTime.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerState.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerTtfbTime.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamPeerUnavailable.emit(ils.Metrics())
	mb.metricNginxStreamUpstreamZombieCount.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordNginxCacheBytesDataPoint adds a data point to nginx.cache.bytes metric.
func (mb *MetricsBuilder) RecordNginxCacheBytesDataPoint(ts pcommon.Timestamp, val int64, nginxCacheOutcomeAttributeValue AttributeNginxCacheOutcome, nginxCacheNameAttributeValue string) {
	mb.metricNginxCacheBytes.recordDataPoint(mb.startTime, ts, val, nginxCacheOutcomeAttributeValue.String(), nginxCacheNameAttributeValue)
}

// RecordNginxCacheMemoryLimitDataPoint adds a data point to nginx.cache.memory.limit metric.
func (mb *MetricsBuilder) RecordNginxCacheMemoryLimitDataPoint(ts pcommon.Timestamp, val int64, nginxCacheNameAttributeValue string) {
	mb.metricNginxCacheMemoryLimit.recordDataPoint(mb.startTime, ts, val, nginxCacheNameAttributeValue)
}

// RecordNginxCacheMemoryUsageDataPoint adds a data point to nginx.cache.memory.usage metric.
func (mb *MetricsBuilder) RecordNginxCacheMemoryUsageDataPoint(ts pcommon.Timestamp, val int64, nginxCacheNameAttributeValue string) {
	mb.metricNginxCacheMemoryUsage.recordDataPoint(mb.startTime, ts, val, nginxCacheNameAttributeValue)
}

// RecordNginxCacheResponsesDataPoint adds a data point to nginx.cache.responses metric.
func (mb *MetricsBuilder) RecordNginxCacheResponsesDataPoint(ts pcommon.Timestamp, val int64, nginxCacheOutcomeAttributeValue AttributeNginxCacheOutcome, nginxCacheNameAttributeValue string) {
	mb.metricNginxCacheResponses.recordDataPoint(mb.startTime, ts, val, nginxCacheOutcomeAttributeValue.String(), nginxCacheNameAttributeValue)
}

// RecordNginxConfigReloadsDataPoint adds a data point to nginx.config.reloads metric.
func (mb *MetricsBuilder) RecordNginxConfigReloadsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricNginxConfigReloads.recordDataPoint(mb.startTime, ts, val)
}

// RecordNginxHTTPConnDataPoint adds a data point to nginx.http.conn metric.
func (mb *MetricsBuilder) RecordNginxHTTPConnDataPoint(ts pcommon.Timestamp, val int64, nginxConnOutcomeAttributeValue AttributeNginxConnOutcome) {
	mb.metricNginxHTTPConn.recordDataPoint(mb.startTime, ts, val, nginxConnOutcomeAttributeValue.String())
}

// RecordNginxHTTPConnCountDataPoint adds a data point to nginx.http.conn.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPConnCountDataPoint(ts pcommon.Timestamp, val int64, nginxConnOutcomeAttributeValue AttributeNginxConnOutcome) {
	mb.metricNginxHTTPConnCount.recordDataPoint(mb.startTime, ts, val, nginxConnOutcomeAttributeValue.String())
}

// RecordNginxHTTPLimitConnRequestsDataPoint adds a data point to nginx.http.limit_conn.requests metric.
func (mb *MetricsBuilder) RecordNginxHTTPLimitConnRequestsDataPoint(ts pcommon.Timestamp, val int64, nginxLimitConnOutcomeAttributeValue AttributeNginxLimitConnOutcome, nginxZoneNameAttributeValue string) {
	mb.metricNginxHTTPLimitConnRequests.recordDataPoint(mb.startTime, ts, val, nginxLimitConnOutcomeAttributeValue.String(), nginxZoneNameAttributeValue)
}

// RecordNginxHTTPLimitReqRequestsDataPoint adds a data point to nginx.http.limit_req.requests metric.
func (mb *MetricsBuilder) RecordNginxHTTPLimitReqRequestsDataPoint(ts pcommon.Timestamp, val int64, nginxLimitReqOutcomeAttributeValue AttributeNginxLimitReqOutcome, nginxZoneNameAttributeValue string) {
	mb.metricNginxHTTPLimitReqRequests.recordDataPoint(mb.startTime, ts, val, nginxLimitReqOutcomeAttributeValue.String(), nginxZoneNameAttributeValue)
}

// RecordNginxHTTPRequestByteIoDataPoint adds a data point to nginx.http.request.byte.io metric.
func (mb *MetricsBuilder) RecordNginxHTTPRequestByteIoDataPoint(ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue AttributeNginxByteIoDirection, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPRequestByteIo.recordDataPoint(mb.startTime, ts, val, nginxByteIoDirectionAttributeValue.String(), nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPRequestDiscardedDataPoint adds a data point to nginx.http.request.discarded metric.
func (mb *MetricsBuilder) RecordNginxHTTPRequestDiscardedDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPRequestDiscarded.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPRequestProcessingCountDataPoint adds a data point to nginx.http.request.processing.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPRequestProcessingCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPRequestProcessingCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPRequestsDataPoint adds a data point to nginx.http.requests metric.
func (mb *MetricsBuilder) RecordNginxHTTPRequestsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPRequests.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPRequestsCountDataPoint adds a data point to nginx.http.requests.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPRequestsCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricNginxHTTPRequestsCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordNginxHTTPResponseStatusDataPoint adds a data point to nginx.http.response.status metric.
func (mb *MetricsBuilder) RecordNginxHTTPResponseStatusDataPoint(ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue AttributeNginxStatusRange, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPResponseStatus.recordDataPoint(mb.startTime, ts, val, nginxStatusRangeAttributeValue.String(), nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPResponsesDataPoint adds a data point to nginx.http.responses metric.
func (mb *MetricsBuilder) RecordNginxHTTPResponsesDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxZoneTypeAttributeValue AttributeNginxZoneType) {
	mb.metricNginxHTTPResponses.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxZoneTypeAttributeValue.String())
}

// RecordNginxHTTPUpstreamKeepaliveCountDataPoint adds a data point to nginx.http.upstream.keepalive.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamKeepaliveCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamKeepaliveCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerByteIoDataPoint adds a data point to nginx.http.upstream.peer.byte.io metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerByteIoDataPoint(ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue AttributeNginxByteIoDirection, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerByteIo.recordDataPoint(mb.startTime, ts, val, nginxByteIoDirectionAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerConnCountDataPoint adds a data point to nginx.http.upstream.peer.conn.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerConnCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerConnCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerCountDataPoint adds a data point to nginx.http.upstream.peer.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerCountDataPoint(ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue AttributeNginxPeerState, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerCount.recordDataPoint(mb.startTime, ts, val, nginxPeerStateAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerFailsDataPoint adds a data point to nginx.http.upstream.peer.fails metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerFailsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerFails.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerHeaderTimeDataPoint adds a data point to nginx.http.upstream.peer.header.time metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerHeaderTimeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerHeaderTime.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerHealthChecksDataPoint adds a data point to nginx.http.upstream.peer.health_checks metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerHealthChecksDataPoint(ts pcommon.Timestamp, val int64, nginxHealthCheckAttributeValue AttributeNginxHealthCheck, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerHealthChecks.recordDataPoint(mb.startTime, ts, val, nginxHealthCheckAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerRequestsDataPoint adds a data point to nginx.http.upstream.peer.requests metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerRequestsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerRequests.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerResponseTimeDataPoint adds a data point to nginx.http.upstream.peer.response.time metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerResponseTimeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerResponseTime.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerResponsesDataPoint adds a data point to nginx.http.upstream.peer.responses metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerResponsesDataPoint(ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue AttributeNginxStatusRange, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerResponses.recordDataPoint(mb.startTime, ts, val, nginxStatusRangeAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerStateDataPoint adds a data point to nginx.http.upstream.peer.state metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerStateDataPoint(ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue AttributeNginxPeerState, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerState.recordDataPoint(mb.startTime, ts, val, nginxPeerStateAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamPeerUnavailablesDataPoint adds a data point to nginx.http.upstream.peer.unavailables metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamPeerUnavailablesDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamPeerUnavailables.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxHTTPUpstreamQueueLimitDataPoint adds a data point to nginx.http.upstream.queue.limit metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamQueueLimitDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamQueueLimit.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxHTTPUpstreamQueueOverflowsDataPoint adds a data point to nginx.http.upstream.queue.overflows metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamQueueOverflowsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamQueueOverflows.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxHTTPUpstreamQueueUsageDataPoint adds a data point to nginx.http.upstream.queue.usage metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamQueueUsageDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamQueueUsage.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxHTTPUpstreamZombieCountDataPoint adds a data point to nginx.http.upstream.zombie.count metric.
func (mb *MetricsBuilder) RecordNginxHTTPUpstreamZombieCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxHTTPUpstreamZombieCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxSlabPageFreeDataPoint adds a data point to nginx.slab.page.free metric.
func (mb *MetricsBuilder) RecordNginxSlabPageFreeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabPageFree.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxSlabPageLimitDataPoint adds a data point to nginx.slab.page.limit metric.
func (mb *MetricsBuilder) RecordNginxSlabPageLimitDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabPageLimit.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxSlabPageUsageDataPoint adds a data point to nginx.slab.page.usage metric.
func (mb *MetricsBuilder) RecordNginxSlabPageUsageDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabPageUsage.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxSlabPageUtilizationDataPoint adds a data point to nginx.slab.page.utilization metric.
func (mb *MetricsBuilder) RecordNginxSlabPageUtilizationDataPoint(ts pcommon.Timestamp, val float64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabPageUtilization.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxSlabSlotAllocationsDataPoint adds a data point to nginx.slab.slot.allocations metric.
func (mb *MetricsBuilder) RecordNginxSlabSlotAllocationsDataPoint(ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxSlabSlotAllocationResultAttributeValue AttributeNginxSlabSlotAllocationResult, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabSlotAllocations.recordDataPoint(mb.startTime, ts, val, nginxSlabSlotLimitAttributeValue, nginxSlabSlotAllocationResultAttributeValue.String(), nginxZoneNameAttributeValue)
}

// RecordNginxSlabSlotFreeDataPoint adds a data point to nginx.slab.slot.free metric.
func (mb *MetricsBuilder) RecordNginxSlabSlotFreeDataPoint(ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabSlotFree.recordDataPoint(mb.startTime, ts, val, nginxSlabSlotLimitAttributeValue, nginxZoneNameAttributeValue)
}

// RecordNginxSlabSlotUsageDataPoint adds a data point to nginx.slab.slot.usage metric.
func (mb *MetricsBuilder) RecordNginxSlabSlotUsageDataPoint(ts pcommon.Timestamp, val int64, nginxSlabSlotLimitAttributeValue int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxSlabSlotUsage.recordDataPoint(mb.startTime, ts, val, nginxSlabSlotLimitAttributeValue, nginxZoneNameAttributeValue)
}

// RecordNginxSslCertificateVerifyFailuresDataPoint adds a data point to nginx.ssl.certificate.verify_failures metric.
func (mb *MetricsBuilder) RecordNginxSslCertificateVerifyFailuresDataPoint(ts pcommon.Timestamp, val int64, nginxSslVerifyFailureReasonAttributeValue AttributeNginxSslVerifyFailureReason) {
	mb.metricNginxSslCertificateVerifyFailures.recordDataPoint(mb.startTime, ts, val, nginxSslVerifyFailureReasonAttributeValue.String())
}

// RecordNginxSslHandshakesDataPoint adds a data point to nginx.ssl.handshakes metric.
func (mb *MetricsBuilder) RecordNginxSslHandshakesDataPoint(ts pcommon.Timestamp, val int64, nginxSslStatusAttributeValue AttributeNginxSslStatus, nginxSslHandshakeReasonAttributeValue AttributeNginxSslHandshakeReason) {
	mb.metricNginxSslHandshakes.recordDataPoint(mb.startTime, ts, val, nginxSslStatusAttributeValue.String(), nginxSslHandshakeReasonAttributeValue.String())
}

// RecordNginxStreamByteIoDataPoint adds a data point to nginx.stream.byte.io metric.
func (mb *MetricsBuilder) RecordNginxStreamByteIoDataPoint(ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue AttributeNginxByteIoDirection, nginxZoneNameAttributeValue string) {
	mb.metricNginxStreamByteIo.recordDataPoint(mb.startTime, ts, val, nginxByteIoDirectionAttributeValue.String(), nginxZoneNameAttributeValue)
}

// RecordNginxStreamConnectionAcceptedDataPoint adds a data point to nginx.stream.connection.accepted metric.
func (mb *MetricsBuilder) RecordNginxStreamConnectionAcceptedDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxStreamConnectionAccepted.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxStreamConnectionDiscardedDataPoint adds a data point to nginx.stream.connection.discarded metric.
func (mb *MetricsBuilder) RecordNginxStreamConnectionDiscardedDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxStreamConnectionDiscarded.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxStreamConnectionProcessingCountDataPoint adds a data point to nginx.stream.connection.processing.count metric.
func (mb *MetricsBuilder) RecordNginxStreamConnectionProcessingCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string) {
	mb.metricNginxStreamConnectionProcessingCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue)
}

// RecordNginxStreamSessionStatusDataPoint adds a data point to nginx.stream.session.status metric.
func (mb *MetricsBuilder) RecordNginxStreamSessionStatusDataPoint(ts pcommon.Timestamp, val int64, nginxStatusRangeAttributeValue AttributeNginxStatusRange, nginxZoneNameAttributeValue string) {
	mb.metricNginxStreamSessionStatus.recordDataPoint(mb.startTime, ts, val, nginxStatusRangeAttributeValue.String(), nginxZoneNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerByteIoDataPoint adds a data point to nginx.stream.upstream.peer.byte.io metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerByteIoDataPoint(ts pcommon.Timestamp, val int64, nginxByteIoDirectionAttributeValue AttributeNginxByteIoDirection, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerByteIo.recordDataPoint(mb.startTime, ts, val, nginxByteIoDirectionAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerConnCountDataPoint adds a data point to nginx.stream.upstream.peer.conn.count metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerConnCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerConnCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerConnTimeDataPoint adds a data point to nginx.stream.upstream.peer.conn.time metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerConnTimeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerConnTime.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerConnsDataPoint adds a data point to nginx.stream.upstream.peer.conns metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerConnsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerConns.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerCountDataPoint adds a data point to nginx.stream.upstream.peer.count metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerCountDataPoint(ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue AttributeNginxPeerState, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerCount.recordDataPoint(mb.startTime, ts, val, nginxPeerStateAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerFailsDataPoint adds a data point to nginx.stream.upstream.peer.fails metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerFailsDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerFails.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue)
}

// RecordNginxStreamUpstreamPeerHealthChecksDataPoint adds a data point to nginx.stream.upstream.peer.health_checks metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerHealthChecksDataPoint(ts pcommon.Timestamp, val int64, nginxHealthCheckAttributeValue AttributeNginxHealthCheck, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerHealthChecks.recordDataPoint(mb.startTime, ts, val, nginxHealthCheckAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerResponseTimeDataPoint adds a data point to nginx.stream.upstream.peer.response.time metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerResponseTimeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerResponseTime.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerStateDataPoint adds a data point to nginx.stream.upstream.peer.state metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerStateDataPoint(ts pcommon.Timestamp, val int64, nginxPeerStateAttributeValue AttributeNginxPeerState, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerState.recordDataPoint(mb.startTime, ts, val, nginxPeerStateAttributeValue.String(), nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerTtfbTimeDataPoint adds a data point to nginx.stream.upstream.peer.ttfb.time metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerTtfbTimeDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerTtfbTime.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamPeerUnavailableDataPoint adds a data point to nginx.stream.upstream.peer.unavailable metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamPeerUnavailableDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string, nginxPeerAddressAttributeValue string, nginxPeerNameAttributeValue string) {
	mb.metricNginxStreamUpstreamPeerUnavailable.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue, nginxPeerAddressAttributeValue, nginxPeerNameAttributeValue)
}

// RecordNginxStreamUpstreamZombieCountDataPoint adds a data point to nginx.stream.upstream.zombie.count metric.
func (mb *MetricsBuilder) RecordNginxStreamUpstreamZombieCountDataPoint(ts pcommon.Timestamp, val int64, nginxZoneNameAttributeValue string, nginxUpstreamNameAttributeValue string) {
	mb.metricNginxStreamUpstreamZombieCount.recordDataPoint(mb.startTime, ts, val, nginxZoneNameAttributeValue, nginxUpstreamNameAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
